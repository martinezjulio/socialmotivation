{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from agents import banditagents\n",
    "from environments import bandits\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dir = '/Users/juliomartinez/Documents/PhD/socialmotivation/configs'\n",
    "num_episodes = 50\n",
    "#solvers = ['EpsilonGreedyAgent']\n",
    "#solvers = ['GreedyAgent']\n",
    "solvers = ['GreedyAgent', 'EpsilonGreedyAgent']\n",
    "environment = 'TwoArmBandit'\n",
    "\n",
    "bandit_config_filename = os.path.join(configs_dir, environment + '.yaml')\n",
    "bandit_config = utils.get_config(bandit_config_filename)\n",
    "env = bandits.Bandit(bandit_config)\n",
    "num_iterations = 1000\n",
    "\n",
    "results_column_names = ['episode','iteration','solver','demonstrator_rewards','learner_rewards','demonstrator_arm_id','learner_arm_id']\n",
    "#best_arm_dist_column_names = ['solver', 'num_episodes', 'num_iterations', 'prob_arm1', 'prob_arm2']\n",
    "\n",
    "\n",
    "for i, solver in enumerate(solvers):\n",
    " \n",
    "    # Get solver class \n",
    "    agentClass = getattr(banditagents, solver)\n",
    "    \n",
    "    # Get config file\n",
    "    agents_config_filename = os.path.join(configs_dir, solver + '.yaml')\n",
    "    agents_config = utils.get_config(agents_config_filename)\n",
    "\n",
    "    demonstrator_best_arm_distribution = np.zeros(env.num_arms)\n",
    "    learner_best_arm_distribution = np.zeros(env.num_arms)\n",
    "\n",
    "    for episode_j in range(num_episodes):\n",
    "        # run demonstrator\n",
    "        demonstrator = agentClass(agents_config['demonstrator'])   \n",
    "        demonstrator(env)\n",
    "        \n",
    "        # run learner\n",
    "        learner = agentClass(agents_config['learner'])\n",
    "        learner(env, demonstrator)\n",
    "\n",
    "        # store results\n",
    "        demonstrator_best_arm_distribution[demonstrator.best_arm_id]=+1\n",
    "        learner_best_arm_distribution[learner.best_arm_id]=+1\n",
    "\n",
    "        num_iterations = agents_config['demonstrator']['num_iterations']\n",
    "        iterations = list(range(num_iterations))\n",
    "        episodes = [episode_j]*num_iterations\n",
    "        solvers_ = [solver]*num_iterations\n",
    "        trial_df = pd.DataFrame(list(zip(episodes, iterations, solvers_, demonstrator.reward_history,learner.reward_history, demonstrator.arm_id_history, learner.arm_id_history)), columns=results_column_names)\n",
    "        if episode_j < 1:\n",
    "            results_df = trial_df.copy()\n",
    "        else:\n",
    "            results_df = pd.concat([results_df,trial_df],axis=0)\n",
    "\n",
    "    demonstrator_best_arm_distribution = demonstrator_best_arm_distribution / np.sum(demonstrator_best_arm_distribution)\n",
    "    learner_best_arm_distribution = learner_best_arm_distribution / np.sum(learner_best_arm_distribution)\n",
    "    solver_df = pd.DataFrame({'solver':solver, 'num_episodes': num_episodes, 'num_iterations': num_iterations, 'prob_arm0':demonstrator_best_arm_distribution[0],'prob_arm1':demonstrator_best_arm_distribution[1]}, index=[0])\n",
    "    if i < 1:\n",
    "        arm_dist_df = solver_df.copy()\n",
    "    else:\n",
    "        arm_dist_df = pd.concat([arm_dist_df,solver_df],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['solver','episode','iteration','demonstrator_rewards','learner_rewards'].groupby(['solver','episode']).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.solver.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julio = banditagents.Person('Julio', \"Martinez\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heather = banditagents.Student('Heather', 'Martinez', 30, 'hat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6d25498612cb4f5f159617db40943c8f1e1957d59ad3740488367ba41964ca3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('socialMot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
