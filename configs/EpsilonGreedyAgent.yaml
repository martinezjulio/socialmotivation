bandit:
  payoffs: [0.6, 0.4]
  sampling_distribution: 'uniform'
demonstrator:
  num_iterations: 1000
  num_initial_iterations: 100
  random_agent: False
  epsilon: 0.2
  decay: 1
  optimistic: False
  social_agent: False
learner:
  num_iterations: 1000
  num_initial_iterations: 100
  random_agent: False
  epsilon: 0.2
  decay: 1
  optimistic: False
  social_agent: True
  observe_simultaneously: True
  observe_action_only: True
  observe_best_arm: True
  prob_observe: # Leave blank for None
  prob_arm_exclusion: 1.0 # Probability to exclude the arms (ignored if observe_best_arm False)